{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN from Scratch\n",
    "\n",
    "This project came to be as the final assignment in a course I took in university. At the time the plan was to port the code from Python to R, which was a cumbersome challenge in itself. Since then I've been trying to learn Julia and what better way to learn than trying to port something I am very familiar with at this point? I will keep the same introduction as I used in the other two notebooks in case anyone ever lands on this notebook first. \n",
    "\n",
    "As a conclusion to the STAN48 course I decided to create simple implementation of a feed forward neural network using mainly Numpy and base Python. While there are already exquisite packages that offer these solutions (like Tensorflow and Pytorch), a step by step implementation of a neural network is still valuable for teaching basic programming concepts as well as basic neural network concepts. The code and explanations presented here are inspired heavily from two sources, namely Andrew Ng's course on [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning), and LUSEM's [Deep Learning and AI Methods](https://www.stat.lu.se/utbildning/kurser/stan47_deep_learning_and_artificial_intelligence_methods) course. The code is then an adaptation of the teachings found in both courses. Additionally, in this project I offer an R version for the project presented here, which can be found in the `R-NN_from_scratch.ipynb` file. As a final disclaimer I must admit that adapting the code in Python was not a hard task, but porting it to R was a strenuous nightmare-like task since the data types can be treated quite differently in both R and Python.\n",
    "\n",
    "As a general example I will use the [Kaggle Dogs vs. Cats](https://www.microsoft.com/en-us/download/details.aspx?id=54765) dataset to classify whether a given picture shows a cat or not. As the data set only includes two different options, we can assume the `not cat` option to be the same as `dog`. As mentioned, the intent is to have a general example to expose how the algorithm works, and the intricasies of the programming challenge, in other words, it is *not* my intention to implement a functioning neural network from scratch **and** a good model for classifying cats. \n",
    "\n",
    "## R or Python? ... Or Julia?\n",
    "\n",
    "This notebook is originally made for Python. One of the requirements for this project was that whatever the choice of application to be developed, it should be done in both Python **and** R. Well, that I did, now I'm doing it for Julia too cause why not. You can check the notebooks for Python an R in this same repository. \n",
    "\n",
    "### The structure\n",
    "\n",
    "This project includes several files. In this notebook you will find the application related functions, however, many of the base functions used for the calculations are left in a separate file that concentrates all the basic calculation functions. Without those dependencies this notebook will not function as it should. Some basic concepts regarding neural networks will be presented through the notebook, but the focus of this work is exposing the programming challenge behind neural networks.\n",
    "\n",
    "### The data\n",
    "\n",
    "The data set contains 25000 images of dogs and cats, but 59 of them were corrupted or in grayscale and, therefore, dropped. The classes are balanced and the angle, depth, light, and dimensions are not uniform. While originally a Kaggle competition data set, I opted to use the version made available by Microsoft because it did not pre divide the data giving me more freedom to split the sets as I please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid_backprop (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function relu(Z)\n",
    "  A = max.(Z, 0)\n",
    "  cache = Z\n",
    "  @assert size(A) == size(Z) \"Sizes don't match in relu function\"\n",
    "  return A, cache\n",
    "end\n",
    "\n",
    "function sigmoid(Z)\n",
    "  A = 1 ./ (1 .+ exp.(Z))\n",
    "  cache = Z\n",
    "  return A, cache\n",
    "end\n",
    "\n",
    "function relu_backprop(dA, cache)\n",
    "  Z = cache\n",
    "  dZ = dA\n",
    "  dZ[Z .<= 0] .= 0\n",
    "  @assert size(dZ) == size(Z) \"Sizes don't match in relu_backprop function\"\n",
    "  return dZ\n",
    "end\n",
    "\n",
    "function sigmoid_backprop(dA, cache)\n",
    "  Z = cache\n",
    "  s = 1 ./ (1 .+ exp.(-Z))\n",
    "  dZ = dA .* s .* (1 .- s)\n",
    "  @assert size(dZ) == size(Z) \"Sizes don't match in sigmoid_backprop function\"\n",
    "  return dZ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"helper_functions.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_param (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_param(layer_dim)\n",
    "  L = length(layer_dim)\n",
    "  parameters = Dict()\n",
    "  for l in 1:(L - 1)\n",
    "    parameters[string(\"W\", l)] = rand(layer_dim[l], layer_dim[l + 1]) * 0.01\n",
    "    parameters[string(\"b\", l)] = zeros(layer_dim[l + 1], 1)\n",
    "    @assert size(parameters[string(\"W\", l)]) == (layer_dim[l], layer_dim[l + 1]) \"Weights size wrong in init_param function\"\n",
    "    @assert size(parameters[string(\"b\", l)]) == (layer_dim[l + 1], 1) \"Bias size wrong in init_param function\"\n",
    "  end\n",
    "  return parameters\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"init_param.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "for_activation (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"helper_functions.jl\")\n",
    "\n",
    "function for_prop(A, W, b)\n",
    "  Z = (W' * A) .+ b\n",
    "  @assert size(Z) == (size(W')[1], size(A)[2])\n",
    "  cache = (A, W, b)\n",
    "  return Z, cache\n",
    "end\n",
    "\n",
    "function for_activation(A_prev, W, b, activ)\n",
    "  if activ == \"sigmoid\"\n",
    "    Z, linear_cache = for_prop(A_prev, W, b)\n",
    "    A, activ_cache = sigmoid(Z)\n",
    "  elseif activ == \"relu\"\n",
    "    Z, linear_cache = for_prop(A_prev, W, b)\n",
    "    A, activ_cache = relu(Z)\n",
    "  end\n",
    "  @assert size(A) == (size(W')[1], size(A_prev)[2]) \"Activation size wrong in for_activation function\"\n",
    "  cache = (linear_cache, activ_cache)\n",
    "  return A, cache\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"for_prop.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep_model (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"for_prop.jl\")\n",
    "\n",
    "function deep_model(X, parameters)\n",
    "  caches = []\n",
    "  A = X\n",
    "  L = div(length(parameters), 2)\n",
    "  for l in 1:(L-1)\n",
    "    A_prev = A\n",
    "    A, cache = for_activation(A_prev,\n",
    "                              parameters[string(\"W\", l)],\n",
    "                              parameters[string(\"b\", l)],\n",
    "                              \"relu\")\n",
    "    push!(caches, cache)\n",
    "  end\n",
    "  AV, cache = for_activation(A,\n",
    "                             parameters[string(\"W\", L)],\n",
    "                             parameters[string(\"b\", L)],\n",
    "                             \"sigmoid\")\n",
    "  push!(caches, cache)\n",
    "  @assert size(AV) == (1, size(X)[2]) \"AV size wrong in deep_model function\"\n",
    "  return AV, caches\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"deep_model.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_computation (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cost_computation(AV, Y)\n",
    "  m = length(Y)\n",
    "  Y = reshape(Y, (length(Y), 1))\n",
    "  cost = -(1/m) * sum(log.(AV) * Y .+ log.((1 .- AV)) * (1 .- Y))\n",
    "  return cost\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"cost_computation.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep_model_back (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"helper_functions.jl\")\n",
    "\n",
    "function back_prop(dZ, cache)\n",
    "  A_prev, W, b = cache\n",
    "  m = size(A_prev)[2]\n",
    "  dW = (1/m) * dZ * A_prev'\n",
    "  db = (1/m) * sum(dZ, dims=2)\n",
    "  dA_prev = W * dZ\n",
    "  @assert size(dA_prev) == size(A_prev) \"dA_prev size wrong in back_prop function\"\n",
    "  @assert size(dW) == size(W') \"dW size wrong in back_prop function\"\n",
    "  @assert size(db) == size(b) \"db size wrong in back_prop function\"\n",
    "  return dA_prev, dW, db\n",
    "end\n",
    "\n",
    "function back_activ(dA, cache, activ)\n",
    "  for_cache, activ_cache = cache\n",
    "  if activ == \"relu\"\n",
    "    dZ = relu_backprop(dA, activ_cache)\n",
    "    dA_prev, dW, db = back_prop(dZ, for_cache)\n",
    "  elseif activ == \"sigmoid\"\n",
    "    dZ = sigmoid_backprop(dA, activ_cache)\n",
    "    dA_prev, dW, db = back_prop(dZ, for_cache)\n",
    "  end\n",
    "  return dA_prev, dW, db\n",
    "end\n",
    "\n",
    "function deep_model_back(AV, Y, caches)\n",
    "  grads = Dict()\n",
    "  L = length(caches)\n",
    "  m = size(AV)[2]\n",
    "  Y = reshape(Y, 1, length(AV))\n",
    "  dAL = -(Y ./ AV) - ((1 .- Y) ./ (1 .- AV))\n",
    "  present_cache = caches[L]\n",
    "  grads[string(\"dA\", L)], grads[string(\"dW\", L)], grads[string(\"db\", L)] = back_activ(dAL, present_cache, \"sigmoid\")\n",
    "  for l in (L - 1):-1:1\n",
    "    present_cache = caches[l]\n",
    "    dA_prev_temp, dW_temp, db_temp = back_activ(grads[string(\"dA\", l+1)], present_cache, \"relu\")\n",
    "    grads[string(\"dA\", l)] = dA_prev_temp\n",
    "    grads[string(\"dW\", l)] = dW_temp\n",
    "    grads[string(\"db\", l)] = db_temp\n",
    "  end\n",
    "  return grads\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"back_prop.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update(params, grads, learning_rate)\n",
    "  parameters = copy(params)\n",
    "  L = div(length(parameters), 2)\n",
    "  for l in 1:L\n",
    "    parameters[string(\"W\", l)] = parameters[string(\"W\", l)] - learning_rate * grads[string(\"dW\", l)]'\n",
    "    parameters[string(\"b\", l)] = parameters[string(\"b\", l)] - learning_rate * grads[string(\"db\", l)]\n",
    "  end\n",
    "  return parameters\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"update.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Images, FileIO, InvertedIndices, Suppressor\n",
    "\n",
    "function process_image(path_vec::Vector{String}, h::Int64, w::Int64, label::Int64)\n",
    "  result = zeros((h*w*3), length(path_vec))\n",
    "  class = Int[]\n",
    "  @suppress begin\n",
    "    for i in enumerate(path_vec) \n",
    "      try\n",
    "        img = load(i[2])\n",
    "      catch \n",
    "        continue\n",
    "      end\n",
    "      img = (img === nothing) ? continue : img\n",
    "      img = imresize(img,(h,w))\n",
    "      img = size(img) == (h, w) ? img : continue\n",
    "      img = vec(img)\n",
    "      try\n",
    "        img = [temp(img[i]) for i = 1:length(img), temp in (red, green, blue)]\n",
    "      catch\n",
    "        continue\n",
    "      end\n",
    "      img = reshape(img, ((h*w*3),1))\n",
    "      result[:,i[1]] = img\n",
    "      push!(class, label)\n",
    "    end\n",
    "  end\n",
    "  return result, class\n",
    "end\n",
    "\n",
    "function create_dataset(filenames_cat::Vector{String}, filenames_dog::Vector{String}, height::Int64, width::Int64, labels)\n",
    "  cat_i, cat_l = process_image(filenames_cat, height, width, labels[1])\n",
    "  dog_i, dog_l = process_image(filenames_dog, height, width, labels[2])\n",
    "  imgs = hcat(cat_i, dog_i)\n",
    "  class = vcat(cat_l, dog_l)\n",
    "  i=1\n",
    "  while i <= size(imgs)[2]\n",
    "    imgs = sum(imgs[:,i]) == 0 ? imgs[:, Not(i)] : imgs\n",
    "    i +=1\n",
    "  end\n",
    "  return imgs, class\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"create_dataset.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense_nn (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"update.jl\")\n",
    "include(\"back_prop.jl\")\n",
    "include(\"deep_model.jl\")\n",
    "include(\"init_param.jl\")\n",
    "include(\"cost_computation.jl\")\n",
    "function dense_nn(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\n",
    "  costs = Float64[]\n",
    "  parameters = init_param(layers_dims)\n",
    "  for i in 1:num_iterations\n",
    "    AV, caches = deep_model(X, parameters)\n",
    "    cost = cost_computation(AV, Y)\n",
    "    grads = deep_model_back(AV, Y, caches)\n",
    "    parameters = update(parameters, grads, learning_rate)\n",
    "    if print_cost && i%100==1 || i==num_iterations-1\n",
    "      println(string(\"Cost after iteration \",i,\": \",cost))\n",
    "    end\n",
    "    if i%100==1 || i==num_iterations\n",
    "      push!(costs, cost)\n",
    "    end\n",
    "  end\n",
    "  return parameters, costs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"dense_nn.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"deep_model.jl\")\n",
    "function predict(X, y, parameters)\n",
    "  m = size(X)[2]\n",
    "  n = div(length(parameters), 2)\n",
    "  p = Int[]\n",
    "  probs, caches = deep_model(X, parameters)\n",
    "  @show size(probs)\n",
    "  for i in 1:size(probs)[2]\n",
    "    if probs[i] > 0.5\n",
    "      push!(p, 1)\n",
    "    else\n",
    "      push!(p, 0)\n",
    "    end\n",
    "  end\n",
    "  print(string(\"Accuracy \", sum((p==y)/m)))\n",
    "  return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"predict.jl\", In[IJulia.n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "include(\"create_dataset.jl\")\n",
    "\n",
    "cat_path = \"C:/Users/wtrindad/source/repos/NN_from_scratch/PetImages/Cat/\"\n",
    "cat_imgs = joinpath.(cat_path, readdir(cat_path))\n",
    "dog_path = \"C:/Users/wtrindad/source/repos/NN_from_scratch/PetImages/Dog/\"\n",
    "dog_imgs = joinpath.(dog_path, readdir(dog_path))\n",
    "\n",
    "img_data, img_label = create_dataset(cat_imgs, dog_imgs, 32, 32, (1,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using StatsBase.predict in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using StatsBase\n",
    "samples = wsample([1, 0], Weights([0.85, 0.15]), size(img_data)[2], replace=true)\n",
    "\n",
    "x_train = img_data[:, samples .== 1]\n",
    "y_train = img_label[samples .== 1]\n",
    "x_test = img_data[:, samples .== 0]\n",
    "y_test = img_label[samples .== 0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(x_train) = (3072, 21242)\n",
      "length(y_train) = 21242\n",
      "size(x_test) = (3072, 3747)\n",
      "length(y_test) = 3747\n"
     ]
    }
   ],
   "source": [
    "@show size(x_train)\n",
    "@show length(y_train)\n",
    "@show size(x_test)\n",
    "@show length(y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 3072\n",
       "   20\n",
       "    7\n",
       "    5\n",
       "    1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = [size(x_train)[1],20,7,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1: 0.6931462031054509\n",
      "costs = [0.6931462031054509]\n"
     ]
    }
   ],
   "source": [
    "include(\"dense_nn.jl\")\n",
    "parameters, costs = dense_nn(x_train, y_train, layer_dims, 0.01, 1, true)\n",
    "@show costs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1: 0.6931448241562331\n",
      "Cost after iteration 101: 67.35089888447875\n",
      "Cost after iteration 149: 68.64504394849563\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = dense_nn(x_train, y_train, layer_dims, 0.15, 150, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(probs) = (1, 21242)\n",
      "Accuracy 0.0"
     ]
    }
   ],
   "source": [
    "include(\"predict.jl\")\n",
    "predict_train = predict(x_train, y_train, parameters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(probs) = (1, 3747)\n",
      "Accuracy 0.0"
     ]
    }
   ],
   "source": [
    "predict_test = predict(x_test, y_test, parameters);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31565927ecfa8a97530e2f965425b5ecaba213cd38f3e141bd6680a742dfc05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
